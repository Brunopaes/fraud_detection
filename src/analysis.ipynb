{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.10\n",
      "  latest version: 4.8.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.10\n",
      "  latest version: 4.8.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.10\n",
      "  latest version: 4.8.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install --yes scikit-learn\n",
    "!conda install --yes matplotlib\n",
    "!conda install --yes seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import linear_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import seaborn\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('../data/datasource.csv').set_index('Ocorrencia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking out duplicate values\n",
    "\n",
    "Assuming that the 'Ocorrencia' is a unique code for the transaction itself. Let's check if there's any duplicated occurrence.\n",
    "\n",
    "```python\n",
    "len(df.index.unique())\n",
    "```\n",
    "If the dataset doesn't present any duplicated values, this piece of code should return, as output, 150.000 data entries. Nevertheless it returned only 64.958 values - meaning that this dataset presents around 85.042 duplicated data entries.\n",
    "\n",
    "```python\n",
    "len(df) - len(df.index.unique())\n",
    "```\n",
    "\n",
    "The duplicated values will be kept on analysis and training in modeling step. Due the nature of this dataset, this duplicate values could have been naturally generated - meaning that one occurrence could occur more than once - or, due the lack of available training material, some transactions could have been artificially generated.\n",
    "\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64958"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of unique values.\n",
    "len(df.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85042"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of duplicated entries.\n",
    "len(df) - len(df.index.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis\n",
    "\n",
    "Section aimed on checking the data distribution and data behaviour.\n",
    "\n",
    "- N.A. values?\n",
    "- Outliers?\n",
    "- Min.\n",
    "- Max.\n",
    "- Mean.\n",
    "- Stdev.\n",
    "\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PP1</th>\n",
       "      <th>PP2</th>\n",
       "      <th>PP3</th>\n",
       "      <th>PP4</th>\n",
       "      <th>PP5</th>\n",
       "      <th>PP6</th>\n",
       "      <th>PP7</th>\n",
       "      <th>PP8</th>\n",
       "      <th>PP9</th>\n",
       "      <th>PP10</th>\n",
       "      <th>...</th>\n",
       "      <th>PP21</th>\n",
       "      <th>PP22</th>\n",
       "      <th>PP23</th>\n",
       "      <th>PP24</th>\n",
       "      <th>PP25</th>\n",
       "      <th>PP26</th>\n",
       "      <th>PP27</th>\n",
       "      <th>PP28</th>\n",
       "      <th>Sacado</th>\n",
       "      <th>Fraude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.058999</td>\n",
       "      <td>-0.000790</td>\n",
       "      <td>-0.192183</td>\n",
       "      <td>-0.037416</td>\n",
       "      <td>0.061588</td>\n",
       "      <td>-0.025715</td>\n",
       "      <td>0.026695</td>\n",
       "      <td>-0.004257</td>\n",
       "      <td>0.028148</td>\n",
       "      <td>-0.003959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009957</td>\n",
       "      <td>0.027398</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>-0.002739</td>\n",
       "      <td>-0.035211</td>\n",
       "      <td>-0.001127</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>-0.001028</td>\n",
       "      <td>-88.602261</td>\n",
       "      <td>0.001580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.894453</td>\n",
       "      <td>1.623712</td>\n",
       "      <td>1.406053</td>\n",
       "      <td>1.397615</td>\n",
       "      <td>1.341265</td>\n",
       "      <td>1.310820</td>\n",
       "      <td>1.194923</td>\n",
       "      <td>1.205874</td>\n",
       "      <td>1.106154</td>\n",
       "      <td>1.075456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739429</td>\n",
       "      <td>0.707714</td>\n",
       "      <td>0.622620</td>\n",
       "      <td>0.606964</td>\n",
       "      <td>0.506130</td>\n",
       "      <td>0.483787</td>\n",
       "      <td>0.397662</td>\n",
       "      <td>0.307684</td>\n",
       "      <td>247.302373</td>\n",
       "      <td>0.039718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.454930</td>\n",
       "      <td>-22.057729</td>\n",
       "      <td>-9.382558</td>\n",
       "      <td>-16.875344</td>\n",
       "      <td>-32.911462</td>\n",
       "      <td>-21.307738</td>\n",
       "      <td>-31.527244</td>\n",
       "      <td>-16.635979</td>\n",
       "      <td>-15.594995</td>\n",
       "      <td>-23.745136</td>\n",
       "      <td>...</td>\n",
       "      <td>-27.202839</td>\n",
       "      <td>-10.503090</td>\n",
       "      <td>-19.002942</td>\n",
       "      <td>-4.022866</td>\n",
       "      <td>-7.519589</td>\n",
       "      <td>-3.220178</td>\n",
       "      <td>-12.152401</td>\n",
       "      <td>-22.620072</td>\n",
       "      <td>-19656.530000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.243456</td>\n",
       "      <td>-0.802149</td>\n",
       "      <td>-1.138473</td>\n",
       "      <td>-0.812624</td>\n",
       "      <td>-0.526469</td>\n",
       "      <td>-0.424574</td>\n",
       "      <td>-0.527260</td>\n",
       "      <td>-0.340863</td>\n",
       "      <td>-0.565387</td>\n",
       "      <td>-0.452162</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165038</td>\n",
       "      <td>-0.466423</td>\n",
       "      <td>-0.128298</td>\n",
       "      <td>-0.431560</td>\n",
       "      <td>-0.369398</td>\n",
       "      <td>-0.247606</td>\n",
       "      <td>-0.090965</td>\n",
       "      <td>-0.078861</td>\n",
       "      <td>-77.662500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.042647</td>\n",
       "      <td>-0.082193</td>\n",
       "      <td>-0.359076</td>\n",
       "      <td>-0.039549</td>\n",
       "      <td>0.124219</td>\n",
       "      <td>0.245177</td>\n",
       "      <td>-0.013129</td>\n",
       "      <td>-0.037083</td>\n",
       "      <td>0.095975</td>\n",
       "      <td>0.096236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033794</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.020008</td>\n",
       "      <td>-0.049357</td>\n",
       "      <td>-0.071030</td>\n",
       "      <td>0.057265</td>\n",
       "      <td>-0.004792</td>\n",
       "      <td>-0.016759</td>\n",
       "      <td>-22.040000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.952018</td>\n",
       "      <td>0.588600</td>\n",
       "      <td>0.555060</td>\n",
       "      <td>0.816575</td>\n",
       "      <td>0.751890</td>\n",
       "      <td>0.734024</td>\n",
       "      <td>0.564334</td>\n",
       "      <td>0.193112</td>\n",
       "      <td>0.678488</td>\n",
       "      <td>0.515473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225362</td>\n",
       "      <td>0.540801</td>\n",
       "      <td>0.164620</td>\n",
       "      <td>0.348762</td>\n",
       "      <td>0.274183</td>\n",
       "      <td>0.331361</td>\n",
       "      <td>0.068544</td>\n",
       "      <td>0.048427</td>\n",
       "      <td>-5.410000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.802320</td>\n",
       "      <td>63.344698</td>\n",
       "      <td>33.680984</td>\n",
       "      <td>5.683171</td>\n",
       "      <td>31.356750</td>\n",
       "      <td>21.929312</td>\n",
       "      <td>43.557242</td>\n",
       "      <td>73.216718</td>\n",
       "      <td>13.434066</td>\n",
       "      <td>24.588262</td>\n",
       "      <td>...</td>\n",
       "      <td>34.830382</td>\n",
       "      <td>10.933144</td>\n",
       "      <td>44.807735</td>\n",
       "      <td>2.824849</td>\n",
       "      <td>10.295397</td>\n",
       "      <td>2.604551</td>\n",
       "      <td>22.565679</td>\n",
       "      <td>11.710896</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PP1            PP2            PP3            PP4  \\\n",
       "count  150000.000000  150000.000000  150000.000000  150000.000000   \n",
       "mean        0.058999      -0.000790      -0.192183      -0.037416   \n",
       "std         1.894453       1.623712       1.406053       1.397615   \n",
       "min        -2.454930     -22.057729      -9.382558     -16.875344   \n",
       "25%        -1.243456      -0.802149      -1.138473      -0.812624   \n",
       "50%         0.042647      -0.082193      -0.359076      -0.039549   \n",
       "75%         0.952018       0.588600       0.555060       0.816575   \n",
       "max        36.802320      63.344698      33.680984       5.683171   \n",
       "\n",
       "                 PP5            PP6            PP7            PP8  \\\n",
       "count  150000.000000  150000.000000  150000.000000  150000.000000   \n",
       "mean        0.061588      -0.025715       0.026695      -0.004257   \n",
       "std         1.341265       1.310820       1.194923       1.205874   \n",
       "min       -32.911462     -21.307738     -31.527244     -16.635979   \n",
       "25%        -0.526469      -0.424574      -0.527260      -0.340863   \n",
       "50%         0.124219       0.245177      -0.013129      -0.037083   \n",
       "75%         0.751890       0.734024       0.564334       0.193112   \n",
       "max        31.356750      21.929312      43.557242      73.216718   \n",
       "\n",
       "                 PP9           PP10  ...           PP21           PP22  \\\n",
       "count  150000.000000  150000.000000  ...  150000.000000  150000.000000   \n",
       "mean        0.028148      -0.003959  ...       0.009957       0.027398   \n",
       "std         1.106154       1.075456  ...       0.739429       0.707714   \n",
       "min       -15.594995     -23.745136  ...     -27.202839     -10.503090   \n",
       "25%        -0.565387      -0.452162  ...      -0.165038      -0.466423   \n",
       "50%         0.095975       0.096236  ...       0.033794       0.014600   \n",
       "75%         0.678488       0.515473  ...       0.225362       0.540801   \n",
       "max        13.434066      24.588262  ...      34.830382      10.933144   \n",
       "\n",
       "                PP23           PP24           PP25           PP26  \\\n",
       "count  150000.000000  150000.000000  150000.000000  150000.000000   \n",
       "mean        0.007275      -0.002739      -0.035211      -0.001127   \n",
       "std         0.622620       0.606964       0.506130       0.483787   \n",
       "min       -19.002942      -4.022866      -7.519589      -3.220178   \n",
       "25%        -0.128298      -0.431560      -0.369398      -0.247606   \n",
       "50%         0.020008      -0.049357      -0.071030       0.057265   \n",
       "75%         0.164620       0.348762       0.274183       0.331361   \n",
       "max        44.807735       2.824849      10.295397       2.604551   \n",
       "\n",
       "                PP27           PP28         Sacado         Fraude  \n",
       "count  150000.000000  150000.000000  150000.000000  150000.000000  \n",
       "mean       -0.000535      -0.001028     -88.602261       0.001580  \n",
       "std         0.397662       0.307684     247.302373       0.039718  \n",
       "min       -12.152401     -22.620072  -19656.530000       0.000000  \n",
       "25%        -0.090965      -0.078861     -77.662500       0.000000  \n",
       "50%        -0.004792      -0.016759     -22.040000       0.000000  \n",
       "75%         0.068544       0.048427      -5.410000       0.000000  \n",
       "max        22.565679      11.710896      -0.000000       1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe Analysis Result\n",
    "\n",
    "This section summarizes the initial analysis on this dataset.\n",
    "\n",
    "The command below allows to summarize each variable and retrieve the main statistical characteristics. \n",
    "\n",
    "```python\n",
    "df.describe()\n",
    "```\n",
    "\n",
    "The first thing to be noticed is at 'Sacado' variable - the amount of money withdrawn. \n",
    "\n",
    "\n",
    "| Statistical Measurement | Value        |\n",
    "| :---------------------: | :----------: |\n",
    "| Mean                    | -88.602261\t |\n",
    "| Standard Deviation      | 247.302373\t |\n",
    "| Min                     | -19656.53    |\n",
    "| Max                     | -0.00        |\n",
    "\n",
    "How can be observed on this chart. The behaviour of 'Sacado' variable is pretty weird. First of all, this variable presents the highest standard deviation of all variables (247.30).\n",
    "\n",
    "```python\n",
    "df.describe().loc['std'].sort_values(ascending=False).head()\n",
    "```\n",
    "\n",
    "The mean, min and max values are pretty strange as well - with all of them being negative or null values. How this values could be negative/null values if this variable it was meant to represent the total withdrawn value of the transaction?\n",
    "\n",
    "__Possible errors:__\n",
    "\n",
    "- Acquistion errors?\n",
    "- Parsing issues?\n",
    "\n",
    "Other variables seems to behave pretty well (well distributed along the mean value - almost a normal curve) - even didn't knowing what they represent (the max values are high? the min values are low?).\n",
    "\n",
    "_obs: Even with the lower deviation. On training, a simple normalization will be made on this dataset._\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sacado    247.302373\n",
       "PP1         1.894453\n",
       "PP2         1.623712\n",
       "PP3         1.406053\n",
       "PP4         1.397615\n",
       "Name: std, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().loc['std'].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PP1</th>\n",
       "      <th>PP2</th>\n",
       "      <th>PP3</th>\n",
       "      <th>PP4</th>\n",
       "      <th>PP5</th>\n",
       "      <th>PP6</th>\n",
       "      <th>PP7</th>\n",
       "      <th>PP8</th>\n",
       "      <th>PP9</th>\n",
       "      <th>PP10</th>\n",
       "      <th>...</th>\n",
       "      <th>PP21</th>\n",
       "      <th>PP22</th>\n",
       "      <th>PP23</th>\n",
       "      <th>PP24</th>\n",
       "      <th>PP25</th>\n",
       "      <th>PP26</th>\n",
       "      <th>PP27</th>\n",
       "      <th>PP28</th>\n",
       "      <th>Sacado</th>\n",
       "      <th>Fraude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ocorrencia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-44477.0</th>\n",
       "      <td>-1.313605</td>\n",
       "      <td>0.829722</td>\n",
       "      <td>-1.021403</td>\n",
       "      <td>0.744870</td>\n",
       "      <td>1.205293</td>\n",
       "      <td>-0.474090</td>\n",
       "      <td>1.346662</td>\n",
       "      <td>-0.313100</td>\n",
       "      <td>0.343039</td>\n",
       "      <td>-0.636555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359877</td>\n",
       "      <td>-1.140092</td>\n",
       "      <td>0.118763</td>\n",
       "      <td>0.255286</td>\n",
       "      <td>-0.402635</td>\n",
       "      <td>0.012719</td>\n",
       "      <td>-0.064429</td>\n",
       "      <td>-0.006987</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-44599.0</th>\n",
       "      <td>0.984284</td>\n",
       "      <td>-0.117687</td>\n",
       "      <td>-1.252511</td>\n",
       "      <td>-0.698290</td>\n",
       "      <td>-2.807570</td>\n",
       "      <td>-4.183633</td>\n",
       "      <td>0.713125</td>\n",
       "      <td>-1.323068</td>\n",
       "      <td>0.441396</td>\n",
       "      <td>0.177385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181102</td>\n",
       "      <td>0.720237</td>\n",
       "      <td>0.158528</td>\n",
       "      <td>-0.972914</td>\n",
       "      <td>-0.576616</td>\n",
       "      <td>0.151814</td>\n",
       "      <td>0.023672</td>\n",
       "      <td>0.009284</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-44763.0</th>\n",
       "      <td>-1.112887</td>\n",
       "      <td>-0.072755</td>\n",
       "      <td>-1.484284</td>\n",
       "      <td>-2.921132</td>\n",
       "      <td>0.892824</td>\n",
       "      <td>-0.369635</td>\n",
       "      <td>0.661314</td>\n",
       "      <td>-0.248757</td>\n",
       "      <td>-0.578535</td>\n",
       "      <td>-0.407350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011709</td>\n",
       "      <td>-0.358025</td>\n",
       "      <td>0.118988</td>\n",
       "      <td>-0.419876</td>\n",
       "      <td>-0.590765</td>\n",
       "      <td>-0.215559</td>\n",
       "      <td>-0.043610</td>\n",
       "      <td>-0.025280</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-44818.0</th>\n",
       "      <td>1.503509</td>\n",
       "      <td>-0.650070</td>\n",
       "      <td>-1.979962</td>\n",
       "      <td>-3.199407</td>\n",
       "      <td>0.183885</td>\n",
       "      <td>-1.864190</td>\n",
       "      <td>1.367814</td>\n",
       "      <td>-0.320220</td>\n",
       "      <td>0.505109</td>\n",
       "      <td>-0.502571</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.031552</td>\n",
       "      <td>-0.808919</td>\n",
       "      <td>0.299368</td>\n",
       "      <td>0.206468</td>\n",
       "      <td>0.547728</td>\n",
       "      <td>-0.419715</td>\n",
       "      <td>-0.168761</td>\n",
       "      <td>0.095962</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-44890.0</th>\n",
       "      <td>0.700064</td>\n",
       "      <td>-0.436402</td>\n",
       "      <td>-1.074464</td>\n",
       "      <td>2.477506</td>\n",
       "      <td>0.047570</td>\n",
       "      <td>1.623677</td>\n",
       "      <td>-0.634653</td>\n",
       "      <td>0.298907</td>\n",
       "      <td>-0.929959</td>\n",
       "      <td>1.417118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096927</td>\n",
       "      <td>-0.247317</td>\n",
       "      <td>0.167330</td>\n",
       "      <td>-0.422878</td>\n",
       "      <td>0.258257</td>\n",
       "      <td>0.294845</td>\n",
       "      <td>0.154354</td>\n",
       "      <td>-0.171619</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-132454.0</th>\n",
       "      <td>2.061483</td>\n",
       "      <td>-1.641567</td>\n",
       "      <td>1.192412</td>\n",
       "      <td>1.722827</td>\n",
       "      <td>-2.902106</td>\n",
       "      <td>-4.638144</td>\n",
       "      <td>0.356431</td>\n",
       "      <td>4.635032</td>\n",
       "      <td>-2.164227</td>\n",
       "      <td>-1.964215</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.635734</td>\n",
       "      <td>1.272928</td>\n",
       "      <td>-0.418075</td>\n",
       "      <td>-0.624839</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>1.045620</td>\n",
       "      <td>2.046863</td>\n",
       "      <td>0.729384</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-132892.0</th>\n",
       "      <td>1.197804</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>-0.150943</td>\n",
       "      <td>0.826385</td>\n",
       "      <td>-2.293986</td>\n",
       "      <td>2.391732</td>\n",
       "      <td>-0.302980</td>\n",
       "      <td>0.227648</td>\n",
       "      <td>-0.056401</td>\n",
       "      <td>0.848129</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116091</td>\n",
       "      <td>0.025749</td>\n",
       "      <td>-0.210352</td>\n",
       "      <td>0.018723</td>\n",
       "      <td>0.485217</td>\n",
       "      <td>0.303273</td>\n",
       "      <td>-0.098812</td>\n",
       "      <td>-0.233373</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-132944.0</th>\n",
       "      <td>0.190846</td>\n",
       "      <td>-0.555578</td>\n",
       "      <td>-1.115820</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>0.171172</td>\n",
       "      <td>0.313610</td>\n",
       "      <td>-0.152727</td>\n",
       "      <td>-0.045064</td>\n",
       "      <td>-0.511116</td>\n",
       "      <td>0.421987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.449453</td>\n",
       "      <td>-1.345258</td>\n",
       "      <td>0.190516</td>\n",
       "      <td>-0.112088</td>\n",
       "      <td>0.344460</td>\n",
       "      <td>0.266088</td>\n",
       "      <td>0.165140</td>\n",
       "      <td>-0.045965</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-133099.0</th>\n",
       "      <td>29.046615</td>\n",
       "      <td>32.362448</td>\n",
       "      <td>3.208013</td>\n",
       "      <td>-11.332812</td>\n",
       "      <td>-15.848810</td>\n",
       "      <td>8.426268</td>\n",
       "      <td>2.832795</td>\n",
       "      <td>2.610682</td>\n",
       "      <td>-3.260821</td>\n",
       "      <td>-4.948269</td>\n",
       "      <td>...</td>\n",
       "      <td>7.835584</td>\n",
       "      <td>-2.253163</td>\n",
       "      <td>-16.722816</td>\n",
       "      <td>-0.695778</td>\n",
       "      <td>-4.381129</td>\n",
       "      <td>-0.654957</td>\n",
       "      <td>-7.126343</td>\n",
       "      <td>2.679944</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-133105.0</th>\n",
       "      <td>-1.951552</td>\n",
       "      <td>0.431578</td>\n",
       "      <td>-0.194441</td>\n",
       "      <td>-1.224964</td>\n",
       "      <td>0.785216</td>\n",
       "      <td>-0.449868</td>\n",
       "      <td>1.179250</td>\n",
       "      <td>-0.321827</td>\n",
       "      <td>-1.586145</td>\n",
       "      <td>-0.165002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211417</td>\n",
       "      <td>-0.742183</td>\n",
       "      <td>-0.212467</td>\n",
       "      <td>-0.424278</td>\n",
       "      <td>0.280602</td>\n",
       "      <td>0.599937</td>\n",
       "      <td>-0.085679</td>\n",
       "      <td>0.015562</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>954 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  PP1        PP2       PP3        PP4        PP5       PP6  \\\n",
       "Ocorrencia                                                                   \n",
       "-44477.0    -1.313605   0.829722 -1.021403   0.744870   1.205293 -0.474090   \n",
       "-44599.0     0.984284  -0.117687 -1.252511  -0.698290  -2.807570 -4.183633   \n",
       "-44763.0    -1.112887  -0.072755 -1.484284  -2.921132   0.892824 -0.369635   \n",
       "-44818.0     1.503509  -0.650070 -1.979962  -3.199407   0.183885 -1.864190   \n",
       "-44890.0     0.700064  -0.436402 -1.074464   2.477506   0.047570  1.623677   \n",
       "...               ...        ...       ...        ...        ...       ...   \n",
       "-132454.0    2.061483  -1.641567  1.192412   1.722827  -2.902106 -4.638144   \n",
       "-132892.0    1.197804   0.787945 -0.150943   0.826385  -2.293986  2.391732   \n",
       "-132944.0    0.190846  -0.555578 -1.115820   0.604743   0.171172  0.313610   \n",
       "-133099.0   29.046615  32.362448  3.208013 -11.332812 -15.848810  8.426268   \n",
       "-133105.0   -1.951552   0.431578 -0.194441  -1.224964   0.785216 -0.449868   \n",
       "\n",
       "                 PP7       PP8       PP9      PP10  ...      PP21      PP22  \\\n",
       "Ocorrencia                                          ...                       \n",
       "-44477.0    1.346662 -0.313100  0.343039 -0.636555  ... -0.359877 -1.140092   \n",
       "-44599.0    0.713125 -1.323068  0.441396  0.177385  ...  0.181102  0.720237   \n",
       "-44763.0    0.661314 -0.248757 -0.578535 -0.407350  ... -0.011709 -0.358025   \n",
       "-44818.0    1.367814 -0.320220  0.505109 -0.502571  ... -1.031552 -0.808919   \n",
       "-44890.0   -0.634653  0.298907 -0.929959  1.417118  ... -0.096927 -0.247317   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "-132454.0   0.356431  4.635032 -2.164227 -1.964215  ... -3.635734  1.272928   \n",
       "-132892.0  -0.302980  0.227648 -0.056401  0.848129  ... -0.116091  0.025749   \n",
       "-132944.0  -0.152727 -0.045064 -0.511116  0.421987  ... -0.449453 -1.345258   \n",
       "-133099.0   2.832795  2.610682 -3.260821 -4.948269  ...  7.835584 -2.253163   \n",
       "-133105.0   1.179250 -0.321827 -1.586145 -0.165002  ... -0.211417 -0.742183   \n",
       "\n",
       "                 PP23      PP24      PP25      PP26      PP27      PP28  \\\n",
       "Ocorrencia                                                                \n",
       "-44477.0     0.118763  0.255286 -0.402635  0.012719 -0.064429 -0.006987   \n",
       "-44599.0     0.158528 -0.972914 -0.576616  0.151814  0.023672  0.009284   \n",
       "-44763.0     0.118988 -0.419876 -0.590765 -0.215559 -0.043610 -0.025280   \n",
       "-44818.0     0.299368  0.206468  0.547728 -0.419715 -0.168761  0.095962   \n",
       "-44890.0     0.167330 -0.422878  0.258257  0.294845  0.154354 -0.171619   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "-132454.0   -0.418075 -0.624839  0.538000  1.045620  2.046863  0.729384   \n",
       "-132892.0   -0.210352  0.018723  0.485217  0.303273 -0.098812 -0.233373   \n",
       "-132944.0    0.190516 -0.112088  0.344460  0.266088  0.165140 -0.045965   \n",
       "-133099.0  -16.722816 -0.695778 -4.381129 -0.654957 -7.126343  2.679944   \n",
       "-133105.0   -0.212467 -0.424278  0.280602  0.599937 -0.085679  0.015562   \n",
       "\n",
       "            Sacado  Fraude  \n",
       "Ocorrencia                  \n",
       "-44477.0      -0.0       0  \n",
       "-44599.0      -0.0       0  \n",
       "-44763.0      -0.0       0  \n",
       "-44818.0      -0.0       0  \n",
       "-44890.0      -0.0       0  \n",
       "...            ...     ...  \n",
       "-132454.0     -0.0       0  \n",
       "-132892.0     -0.0       0  \n",
       "-132944.0     -0.0       0  \n",
       "-133099.0     -0.0       0  \n",
       "-133105.0     -0.0       0  \n",
       "\n",
       "[954 rows x 30 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Sacado >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some plots\n",
    "\n",
    "On this section are plots for visualizing the dispersion of some 'random' variables.\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1a2770d5f8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1a26cabf60>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x1a26b9f0f0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1a27136240>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3df5BdZZ3n8fdHIsgGlWCkJ0PiJNbEqUJSIukFqlitVsYQcMZgjbggZYKwE5clJdZkXYK4CytgBWfQlSkXjBINrhopEclKMARI61pLNAkiEH5MWshISCoxBDANiNv43T/O0+Skc07/uH3vPae7P6+qrr73e55z7nNvP6e/93nOj0cRgZmZWZHXVV0BMzOrLycJMzMr5SRhZmalnCTMzKyUk4SZmZVykjAzs1JOEmZmVspJYhyRtF3Sy5J6Je2W9E1JR0nqlvSHFN8r6YeSpqV13idpg6QXJG2v+C2YjUiDbf4zkh6RtF/SU5I+U/X7qDMnifHnbyPiKOAk4N8Cn0vxJSn+DuBo4Msp/iKwEvCOYmPVSNu8gIXAFGA+sETSue2t8tjhJDFORcQzwF3ACQPi+4Db+uMR8cuI+DbwZNsradZEI2jzX4yIByKiLyKeAO4ATmt3fccKJ4lxStIM4CzgVwPiU4G/Gxg3G+saafOSBLwH2NqOOo5FThLjz48kPQ/8HPgp8IUUvyHFfw3sAv6hovqZNdto2vxVZP8Hv9mGeo5Jk6qugDXd2RFxTz6QfVniUxHxjWqqZNZSDbV5SUvIjk28JyJeaW0Vxy4nCTObcCRdCCwD3hsRO6quT505SUxwkl4HHA68PnuqNwB/iog/Vlszs9aQdD7ZkNT7IsInbAzBxyTsvcDLwFrgbenx3ZXWyKy1rgHeAmxK11H0Srqp6krVlTzpkJmZlXFPwszMSjlJmJlZKScJMzMr5SRhZmalxt0psFOnTo2ZM2c2tO6LL77I5MmTm1uhMWqifxZbtmz5A7Af2BMRJwBIugr4e+B3qdhnI2JtWnY5cBHwKtlFXOtSfD7wFeAw4BsRsTzFZwGrgWOAB4CPR8QfJR0B3ALMBZ4F/n1EbB+srv1tvs5/M9dt5Npdry1btuyNiLcesiAixtXP3Llzo1EbNmxoeN3xZqJ/FsDjZHcVfSRS2yK7hcN/jgFtDjie7NYPRwCzgN+QJYXD0uO3k12L8mvg+LTOrcC56fFNwMXp8X8CbkqPzwW+P/D1Bv70t/k6/81ct5Frd72AzVHQvjzcZFasF9g3zLILgNUR8UpEPAX0ACenn56IeDKyixNXAwvSTeXeD/wgrb8KODu3rVXp8Q+A01N5s0qMu+EmsxZbImkhsBlYGhHPAccBG3NldqQYwNMD4qeQXcj1fET0FZQ/rn+diOiT9EIqvzdfCUmLgcUAHR0ddHd309vbS3d3d1PeZLO5biNXl3o5SZgN343A1UCk39cDF5JNYjNQUHxiSAxSniGWHQhErABWAHR2dkZXVxfd3d10dXUN8Raq4bqNXF3qNaGSxMxldw66fOmcPi4YUGb78g+2sko2hkTE7v7Hkr4O/Dg93QHMyBWdDuxMj4vie4GjJU1KvYl8+f5t7ZA0CXgzwx/2qkwj+xZ4/xoLfEzCbJj650hOPgw8kh6vAc6VdEQ6a2k28EtgEzBb0ixJh5MdiF6TDhJuAD6S1l9ENjta/7YWpccfAe5L5c0qMaF6EmYjMAu4H5gqaQdwJdAl6USy4Z/twCcBImKrpFuBR4E+4JKIeBVem7NgHdmZTisjon8GtMuA1ZKuIZsx7eYUvxn4tqQesh6E5162SjlJmBV7KiI6B8RuLiwJRMS1wLUF8bVkd9gdGH+S7OyngfE/AOeMuLZmLeLhJjMzK+UkYWZmpZwkzMyslJOEmZmVcpIwM7NSThJmZlbKScLMzEo5SZiZWSknCTMzK+UkYWZmpZwkzMyslJOEmZmVGjJJSFopaY+kR3KxYyStl7Qt/Z6S4pJ0g6QeSQ9JOim3zqJUfpukRbn4XEkPp3Vu6J+qsew1zMysfYbTk/gWMH9AbBlwb0TMBu5NzwHOJLuX/myyqRVvhOwfPtmtlk8hu/Pllbl/+jemsv3rzR/iNczMrE2GTBIR8TMOnRkrP1n7wEncb4nMRrLZt6YBZwDrI2JfmhN4PTA/LXtTRNyfJla5heIJ4fOvYWZmbdLofBIdEbELICJ2STo2xV+bxD3pn+B9sPiOgvhgr3GIoknhiyyd01cYf+1NHXlomTpMRF6FukzCbmbVavakQ2WTuI80PiJFk8IXKZpjN2/pnD6uf/jgj2T7+cXbGu/qMgm7mVWr0bObdvfP95t+70nxsgnhB4tPL4gP9hpmZtYmjSaJ/GTtAydxX5jOcjoVeCENGa0D5kmakg5YzwPWpWX7JZ2azmpaSPGE8PnXMDOzNhlyuEnS94AuDp4Qfjlwq6SLgN9yYE7etcBZQA/wEvAJgIjYJ+lqYFMq9/mI6D8YfjHZGVRHAnelHwZ5DTMza5Mhk0REnFey6PSCsgFcUrKdlcDKgvhm4ISC+LNFr2FmZu3jK67Nis30RaRmThJmZfbii0jNnCTMSvTii0jNmn6dhNl4VpuLSIsuIK3yAshGLlSFelysWtcLR+tSLycJs9Fr+0WkRReQVnkBZCMXqkI9Llat64WjdamXh5vMhs8XkdqE4yRhNny+iNQmHA83mRWbBdyPLyK1Cc5JwqzYUxHRWRD3RaQ2oXi4yczMSjlJmJlZKScJMzMr5SRhZmalnCTMzKyUk4SZmZVykjAzs1JOEmZmVspJwszMSjlJmJlZKScJMzMr5SRhZmalnCTMzKyUk4SZmZVykjAzs1JOEmZmVspJwszMSo0qSUjaLulhSQ9K2pxix0haL2lb+j0lxSXpBkk9kh6SdFJuO4tS+W2SFuXic9P2e9K6Gk19zcxsZJrRk3hfRJyYm+pxGXBvRMwG7k3PAc4EZqefxcCNkCUVsvmDTwFOBq7sTyypzOLcevObUF8zMxumVgw3LQBWpcergLNz8VsisxE4WtI04AxgfUTsi4jngPXA/LTsTRFxf5pD+JbctszMrA1GmyQCuFvSFkmLU6wjInYBpN/HpvhxwNO5dXek2GDxHQVxMzNrk0mjXP+0iNgp6VhgvaTHBylbdDwhGogfuuEsQS0G6OjooLu7u7ACS+f0DVI96Djy0DJl2xrvent7J+x7N7MDRpUkImJn+r1H0u1kxxR2S5oWEbvSkNGeVHwHMCO3+nRgZ4p3DYh3p/j0gvJF9VgBrADo7OyMrq6uomJcsOzOQd/P0jl9XP/wwR/J9vOLtzXedXd3U/Y5TnSStgP7gVeBvojoTMfWvg/MBLYDH42I59LJFl8BzgJeAi6IiAfSdhYBn0ubvSYiVqX4XOBbwJHAWuDSNORq1nYNDzdJmizpjf2PgXnAI8AaoP8MpUXAHenxGmBhOsvpVOCFNBy1DpgnaUo6YD0PWJeW7Zd0atrRFua2ZVY1n7BhE8JoehIdwO3prNRJwHcj4ieSNgG3SroI+C1wTiq/luzbVA/ZN6pPAETEPklXA5tSuc9HxL70+GIOfKO6K/2Y1dECDvSIV5H1hi8jd8IGsFFS/wkbXaQTNgAk9Z+w0U06YSPF+0/YcNu3SjScJCLiSeBdBfFngdML4gFcUrKtlcDKgvhm4IRG62jWIv0nbATwtTTcedAJG+k4HbTohI2i43BVHkdq5Hgf1OOYX12Pv9WlXqM9cG02EVV+wkbRcbgqjyM1crwP6nHMr67H3+pSL9+Ww2yE8idsAAedsAEwghM2yuLDOmHDrB2cJMxGwCds2ETj4SazkfEJGzahOEmYjYBP2LCJxsNNZmZWyknCzMxKOUmYmVkpJwkzMyvlJGFmZqWcJMzMrJSThJmZlXKSMDOzUk4SZmZWyknCzMxKOUmYmVkp37tpCDOHuE9+ke3LP9iCmpiZtZ97EmZmVspJwszMSjlJmJlZKScJMzMr5SRhZmalnCTMzKyUk4SZmZVykjAzs1JOEmZmVspJwszMStU+SUiaL+kJST2SllVdH7N2cLu3uqj1vZskHQZ8FfgAsAPYJGlNRDxabc3MWmcitXvfG63+ap0kgJOBnoh4EkDSamABUOudxQ3fRqnSdt9I+7Xxq+5J4jjg6dzzHcApAwtJWgwsTk97JT3RyIt9CqYCextZd7R0XRWvOqjKPoua+IsKX3vIdl/S5mv7N2vmvtWCfaWun1u761XY5uueJFQQi0MCESuAFaN+MWlzRHSOdjvjgT+LSg3Z7ovafJ3/Zq7byNWlXnU/cL0DmJF7Ph3YWVFdzNrF7d5qo+5JYhMwW9IsSYcD5wJrKq6TWau53Vtt1Hq4KSL6JC0B1gGHASsjYmsLX3LUQ1bjiD+Lioyi3df5b+a6jVwt6qWIQ4b4zczMgPoPN5mZWYWcJMzMrJSTBL4FgqQZkjZIekzSVkmXpvgxktZL2pZ+T6m6rnYoSf8o6XFJD0m6XdLRKT5T0suSHkw/N1VQt9rsW4O086skPZP7nM6qqH7bJT2c6rA5xSrfByf8MYl0C4R/IXcLBOC88XgLhDKSpgHTIuIBSW8EtgBnAxcA+yJiedrBp0TEZRVW1QpImgfclw54XwcQEZdJmgn8OCJOqKhetdq3BmnnHwV6I+KfqqhXrn7bgc6I2JuLfZGK90H3JHK3QIiIPwL9t0CYMCJiV0Q8kB7vBx4ju+p3AbAqFVtFtkNZzUTE3RHRl55uJLuuog5qtW8N0s7rrPJ90Emi+BYIdW84LZO+fb4b+AXQERG7INvBgGOrq5kN04XAXbnnsyT9StJPJb2nzXWp7b41oJ0DLEnDdSsrHFYN4G5JW9JtV6AG+2Ctr5Nok2Hd+mMikHQUcBvw6Yj4vVT00VgVJN0D/FnBoisi4o5U5gqgD/hOWrYLeFtEPCtpLvAjSe+MiN+3pdI13bcK2vmNwNVkdbsauJ4s2bbbaRGxU9KxwHpJj1dQh0M4SfgWCABIej3ZjvOdiPhhCu+WNC0idqXx3D3V1XBii4i/Hmy5pEXA3wCnRzrQGBGvAK+kx1sk/QZ4B7C5xdXtV7t9q6idR8Tu3PKvAz+uom4RsTP93iPpdrLhusr3QQ83jeFbIKSzIV6W1Ctpt6RvSjpKUrekP6T4Xkk/TA0MSZ+R9Iik/ZKeSs8F3Ew2RjslnWHRR3YHykXp5RYBd1TyRm1QkuYDlwEfioiXcvG3poPHSHo7MBt4so1Va/m+1cA+0N/OuyX9LC3/Xf+ZTsCHgUeaWcdhvo/J6WA6kiYD81I91lD1PhgRE/4HOIvsLIzfkHXfK6/TMOu9Hfjr9Pg4ska1HOgG/kOKHwPcB6xOz/8LcBJZL/KvgH8FriTraj+Unv8GuB+4DrgX2JZ+H1P1e/ZPYTvoIRv7fzD93JTifwdsBX4NPAD8bQV1a+m+NcJ94J7UzrcC/y+19Q8B30t1fIjsn/K0Cj6nt6e/069T/a5I8bdUvQ96uAmIiLXA2qrrMRoR8Yyku4ATBsT3SboNuDg9/2Ju8ROS7gCmRsRB48eS/hfwckSc3uKq2yhFxF+WxG8jG1qpTDv3reHsAxEhSV8AZkTEx1ORykcOIptg6l0F8WeBSvdBDzeNE5JmkH1r+9WA+FSyb5S/KlhHwHvIvrmYjWkj2AdOBfZJ+r+S9kj635Le1t7ajh1OEmPfjyQ9D/wc+CnwhRS/IcV/TXaWyz8UrHsVWRv4ZhvqadYqI90HppON718KvA14imzIyQp4uGnsOzsi7skH0qmrn4qIb5StpOxW1AuB90R2FozZWDXSfeBl4PaI2JTK/ndgr6Q3R8QLLa/tGOMkMQFJuhBYBrw3InZUXR+zNnuIg6/X6H/sC4MKeLhpgpF0Pll3/APpYNnA5a+X9AaytjFJ0hv6T6M0Gye+CXxY0onpuon/Cvw8Ip6vuF615CQx8VxDdlrdpnSOeK8Ovjvo18m64+cBV6THHz90M2ZjU0TcB3wWuJPs4rS/BD5WaaVqbMLfBdbMzMq5J2FmZqWcJMzMrJSThJmZlXKSMDOzUuPuOompU6fGzJkzm77dF198kcmTJzd9u60wVupa53pu2bJlb0S8tep6DMdI2nydP/NW8XsentI2P4y7E64kO03skVzsKuAZDtx18qzcssvJ7kr5BHBGLj4/xXqAZbn4LLLZobYB3wcOT/Ej0vOetHzmcO5YOHfu3GiFDRs2tGS7rTBW6lrnegKbo81322z0ZyRtvs6feav4PQ9PWZsfznDTt9I/+IG+HBEnpp+1AJKOJ7tn/DvTOv9T0mHpYqyvAmcCxwPnpbKQ3Y76yxExG3gOuCjFLwKei+wOl19O5czMrI2GTBIR8TNg3zC3t4Bs3oJXIuIpsl7AyZRMiJ7uQvp+4Adp/fxE3/kJwH8AnC7Pp2lm1lajOSaxRNJCsqkQl0bEc2STfmzMlclPfD5wQvRTyK78fT4i+grKvzaJekT0SXohld87sCJp0vDFAB0dHXR3d4/ibRXr7e1tyXZbYazUdazU02wiazRJlE0cXjbxeVGPJQYpzxDLDg5GrABWAHR2dkZXV9cgVW9Md3c3rdjuaMxcdmdhfOmcV7n+5y+Wrrd9+QdbVaURqeNnOhhJf0V2nKzf24H/BhwN/D3wuxT/bG4I9nKyodNXye5Kui7F5wNfAQ4DvhERy1N8FllP+xiy2eQ+nnrflpS1+zJL5/TR1ZqqTAgNnQIbEbsj4tWI+BPZvX5OTovKJj4vi+8FjpY0aUD8oG2l5W9m+MNeZk0XEU/0H4cD5gIvAbenxa0+RmdWiYaSRJpQvF9+4vA1wLmSjkjfiGYDv6RkQvR0RH0D8JG0fn6i7/wE4B8B7kvlzergdOA3EfGvg5Rp5jE6s0oMOdwk6XtAFzBV0g7gSqBL0olkwz/bgU8CRMRWSbcCjwJ9wCUR8WrazhJgHVn3emVE9E+ZeRmwWtI1ZNML3pziNwPfltRD1oM4d9Tv1qx5zuXg2cxafYzuII0ehxsPx4GWzukbulBOx5GM+fc8Us38Ow+ZJCLivILwzQWx/vLXAtcWxAsnRI9sToOTC+J/AM4Zqn5m7ZZ6wx8iuyYI2nOM7uBgg8fhxtpxoCIXNHBM4qNj/D2PVDP/zuPuimuzNjgTeCAidkN2jK5/gaSvAz9OT8uOxVESf+0YXepN5MubVcL3bjIbufPIDTW16RidWSXckzAbAUn/BvgA6Thc8sU2HKMzq4SThNkIRMRLZAeY87HS6V2bdYzOrCpOEmY27o30Ajyoz0WnVfMxCTMzK+UkYWZmpZwkzMyslJOEmZmVcpIwM7NSThJmZlbKScLMzEo5SZiZWSknCTMzK+UkYWZmpZwkzMyslJOEmZmVcpIwM7NSThJmZlbKScLMzEo5SZiZWakhk4SklZL2SHokFztG0npJ29LvKSkuSTdI6pH0kKSTcussSuW3SVqUi8+V9HBa5wZJGuw1zMysfYbTk/gWMH9AbBlwb0TMBu5NzwHOJJvsfTawGLgRsn/4wJXAKWRTM16Z+6d/Yyrbv978IV7DzMzaZMgkERE/A/YNCC8AVqXHq4Czc/FbIrMROFrSNOAMYH1E7IuI54D1wPy07E0RcX9EBHDLgG0VvYaZmbVJo3Ncd0TELoCI2CXp2BQ/Dng6V25Hig0W31EQH+w1DiFpMVlvhI6ODrq7uxt8W+V6e3tbst3RWDqnrzDecWT5MqA276OOn+lwSNoO7AdeBfoiojP1lr8PzAS2Ax+NiOfS8OlXgLOAl4ALIuKBtJ1FwOfSZq+JiFUpPpesB38ksBa4NH2JMmu7RpNEGRXEooH4iETECmAFQGdnZ3R1dY10E0Pq7u6mFdsdjQtKJndfOqeP6x8u/9NuP7+rRTUamTp+piPwvojYm3vePzy6XNKy9PwyDh6CPYVsePWU3BBsJ1mb3yJpTepp9w/BbiRLEvOBu9rztswO1ujZTbvTUBHp954U3wHMyJWbDuwcIj69ID7Ya5jVUTuGYM3artGexBpgEbA8/b4jF18iaTXZt6YX0lDROuALuYPV84DLI2KfpP2STgV+ASwE/nmI1zCrWgB3Swrga6kn244h2Nc0OsQ6Vof48gYbSi0y1PBrmbH8OTXz7zxkkpD0PaALmCppB1kXeTlwq6SLgN8C56Tia8nGXnvIxl8/AZCSwdXAplTu8xHRfzD8Yg6Mv97FgW512WuYVe20iNiZEsF6SY8PUrYlQ7CNDrGO8SE+oHyYtcxQw69l6jIs24hm/p2H/OQi4rySRacXlA3gkpLtrARWFsQ3AycUxJ8teg2zqkXEzvR7j6TbyU7r3i1pWupFDHcItmtAvJvBh2DN2s5XXJuNgKTJkt7Y/5hs6PQRDgyPwqFDsAvThaankoZggXXAPElT0jDsPGBdWrZf0qnpzKiFeKjVKtTss5vMxrsO4PZ0Y4BJwHcj4ieSNtH6IViztnOSMBuBiHgSeFdBvHB4tJlDsGZV8HCTmZmVcpIwM7NSThJmZlbKScLMzEo5SZiZWSknCTMzK+UkYWZmpZwkzMyslJOEmZmVcpIwM7NSThJmZlbKScLMzEo5SZiZWSknCTMzK+UkYWZmpZwkzMyslJOEmZmVcpIwM7NSo0oSkrZLeljSg5I2p9gxktZL2pZ+T0lxSbpBUo+khySdlNvOolR+m6RFufjctP2etK5GU18zMxuZZvQk3hcRJ0ZEZ3q+DLg3ImYD96bnAGcCs9PPYuBGyJIKcCVwCnAycGV/YkllFufWm9+E+pqZ2TC1YrhpAbAqPV4FnJ2L3xKZjcDRkqYBZwDrI2JfRDwHrAfmp2Vvioj702Tyt+S2ZdZ2kmZI2iDpMUlbJV2a4ldJeib1qB+UdFZunctTT/gJSWfk4vNTrEfSslx8lqRfpF719yUd3t53aXawSaNcP4C7JQXwtYhYAXRExC6AiNgl6dhU9jjg6dy6O1JssPiOgvghJC0m63HQ0dFBd3f3KN/WoXp7e1uy3dFYOqevMN5xZPkyoDbvo46f6RD6gKUR8YCkNwJbJK1Py74cEf+ULyzpeOBc4J3AnwP3SHpHWvxV4ANk7XqTpDUR8ShwXdrWakk3AReRet1mVRhtkjgtInamRLBe0uODlC06nhANxA8NZslpBUBnZ2d0dXUNWulGdHd304rtjsYFy+4sjC+d08f1D5f/abef39WiGo1MHT/TwaQvP/1fgPZLeoySLy7JAmB1RLwCPCWph2xIFaAnIp4EkLQaWJC2937gY6nMKuAqnCSsQqNKEhGxM/3eI+l2sh1gt6RpqRcxDdiTiu8AZuRWnw7sTPGuAfHuFJ9eUN6scpJmAu8GfgGcBiyRtBDYTNbbeI4sgWzMrZbvDQ/sPZ8CvAV4PiL6CsoPfP2Ges9jsPd2iMF6yUWG6lmXGcufUzP/zg0nCUmTgdelb1STgXnA54E1wCJgefp9R1plDdmOtJpsh3ghJZJ1wBdyB6vnAZdHxD5J+yWdSrYjLgT+udH6mjWLpKOA24BPR8TvJd0IXE3W070auB64kPLecNGxwLb0nsda761IWQ+6zFA96zJ16XE3opl/59H0JDqA29NZqZOA70bETyRtAm6VdBHwW+CcVH4tcBbQA7wEfAIgJYOrgU2p3OcjYl96fDHwLeBI4K70Y1YZSa8nSxDfiYgfAkTE7tzyrwM/Tk/Les+UxPeSndAxKfUm3Hu2yjWcJNJ46rsK4s8CpxfEA7ikZFsrgZUF8c3ACY3W0ayZ0nU6NwOPRcSXcvFp/SdrAB8GHkmP1wDflfQlsgPXs4FfkvUYZkuaBTxDdnD7YxERkjYAHwFWc3BP3KwSoz1wbTaRnAZ8HHhY0oMp9lngPEknkg0NbQc+CRARWyXdCjxKdmbUJRHxKoCkJcA64DBgZURsTdu7DFgt6RrgV2RJyawyThJmwxQRP6f4uMHaQda5Fri2IL62aL3UQz95YNysKr53k5mZlXKSMDOzUk4SZmZWyknCzMxKOUmYmVkpJwkzMyvlJGFmZqWcJMzMrJSThJmZlXKSMDOzUk4SZmZWyknCzMxKOUmYmVkpJwkzMyvlJGFmZqWcJMzMrJSThJmZlXKSMDOzUk4SZmZWyknCzMxKTaq6AkORNB/4CnAY8I2IWF5xlcxabqK0+5nL7qy6CjaEWvckJB0GfBU4EzgeOE/S8dXWyqy13O6tTurekzgZ6ImIJwEkrQYWAI9WWqsW8Dcqy5kw7d7qr+5J4jjg6dzzHcApAwtJWgwsTk97JT3RgrpMBfa2YLtN96kh6qrr2liZwdX5M/2LCl97yHY/ijZf58+8JYbaH8rUaD9pRCPvubDN1z1JqCAWhwQiVgArWloRaXNEdLbyNZplrNR1rNSzAkO2+0bb/ET8zP2eR6fWxyTIvkHNyD2fDuysqC5m7eJ2b7VR9ySxCZgtaZakw4FzgTUV18ms1dzurTZqPdwUEX2SlgDryE4FXBkRWyuqTkuHs5psrNR1rNSzrVrc7ifiZ+73PAqKOGSI38zMDKj/cJOZmVXIScLMzEo5SQxB0j9KelzSQ5Jul3R0btnlknokPSHpjCrrmeozP9WlR9KyquuTJ2mGpA2SHpO0VdKlKX6MpPWStqXfU6qu63gzltpws9V5n2iWVu9bPiYxBEnzgPvSwcTrACLisnSbhO+RXR3758A9wDsi4tWK6nkY8C/AB8hOodwEnBcRtbhKV9I0YFpEPCDpjcAW4GzgAmBfRCxPO/GUiLiswqqOO2OlDTdb3feJZmn1vuWexBAi4u6I6EtPN5Kdsw7ZbRJWR8QrEfEU0EO2s1XltVs5RMQfgf5bOdRCROyKiAfS4/3AY2RXFi8AVqViq8gatzXRGGrDzVbrfaJZWr1vOUmMzIXAXelx0a0Tjmt7jQ6oW31KSZoJvBv4BdAREbsga+zAsdXVbEKocxtutvH+/g7Rin2r1tdJtIuke4A/K1h0RUTckcpcAfQB3+lfraB8lWN3datPIUlHAbcBn46I30tF1baRGidtuNnG+/s7SKv2LScJICL+erDlkhYBfwOcHgcO4tTt1gl1q88hJL2erBF/JyJ+mMK7JU2LiF1pbHVPdTUcu8ZJG2628f7+XtPKfW8KSH0AAADQSURBVMvDTUNIk79cBnwoIl7KLVoDnCvpCEmzgNnAL6uoY1LrWzko+1pzM/BYRHwpt2gNsCg9XgTc0e66jXdjqA03W633iWZp9b7ls5uGIKkHOAJ4NoU2RsR/TMuuIBvj7SPr4t1VvJX2kHQW8D84cCuHa6usT56kfwf8H+Bh4E8p/FmysdNbgbcBvwXOiYh9lVRynBpLbbjZ6rxPNEur9y0nCTMzK+XhJjMzK+UkYWZmpZwkzMyslJOEmZmVcpIwM7NSThJmZlbKScLMzEr9f5m8MtmRYH3nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[['PP1', 'PP2', 'PP6', 'PP21']].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a27d9ee48>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# As it can be observed. The Sacado variable has a lot of outliers - removing and analysing it alone \n",
    "# (for not disturbing the scale)\n",
    "df[['PP1', 'PP2', 'PP21', 'PP6', 'Sacado']].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a26d074e0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There are outliers on it - predicted it on histogram.\n",
    "df[['PP1', 'PP2', 'PP6', 'PP21']].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1e6e45c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD4CAYAAAD//dEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAatElEQVR4nO3df5BdZZ3n8feH7hA1KkjAJpMGEoc41aG1KOnyBxWtjgENs84E2LCmQdO76aoMLISs1pZAtbtlKW0Bs2qho2LcZkws7YQJGxJHHCTYdzSrQYNkgNBmaIKQJpQSQCRRE7vz3T/u0+xJcpOczu17b9/weVXduud+n3NOP7fqhg/P+fUoIjAzMzuWk2rdATMzqw8ODDMzy8WBYWZmuTgwzMwsFweGmZnl0ljrDlTK6aefHjNmzKh1N8xK2rt3L1OmTKl1N8wO89BDD+2OiDNKtZ2wgTFjxgy2bNlS626YlVQoFGhvb691N8wOI+npI7X5kJSZmeXiwDAzs1wcGGZmlosDw8zMcnFgmJlZLnUVGJLmS9ouaVDSjbXuj5nZa0ndBIakBuCrwCXAbKBD0uza9srM7LWjnu7DeDcwGBE7ACStBhYAj9e0V2ZjIOmwmqcYsHpRT4ExHdiZ+TwEvCe7gqSlwFKApqYmCoVC1TpnJ4ZlTy+r6P5bv9V6WO0dK99Rsb/3lXO+UrF922tPPQXG4f9rBgf9r1lErABWALS1tYXvpLWxeuXGWyq276dv/cgR28654Z/H/e+d8vpJtHe2j/t+7bWrngJjCDgr87kZ2FWjvtgJ6te3/Icxb1PqMNNYHS1MRvnQldVaPQXGL4BZkmYCzwKLgCtr2yWz/P8hP1qwOAysHtRNYETEsKTrgPuABuDOiNhW426Zmb1m1E1gAETEvcC9te6HmdlrUd3ch2FmZrXlwDAzs1wcGGZmlosDw8zMcnFgmJlZLg4MMzPLxYFhZma5ODDMzCwXB4aZmeXiwDAzs1wcGGZmlosDw8zMcnFgmJlZLg4MMzPLxYFhZma5ODDMzCyXigWGpL+X9CtJj0haJ+nUVJ8h6Y+StqbXHZltLpD0qKRBSV9WmtNS0mmS7pf0RHp/S6X6bWZmpVVyhHE/0BoR7wT+Hbgp0/ZkRJyfXldn6l8HlgKz0mt+qt8IPBARs4AH0mczM6uiigVGRPwwIobTx81A89HWlzQNeHNE/CwiAlgFXJqaFwAr0/LKTN3MzKqkWnN6LwHWZD7PlPQw8Hvg0xHxE2A6MJRZZyjVAJoi4jmAiHhO0ltL/RFJSymOUGhqaqJQKIzrlzCrFP9WrR6UFRiSNgJnlmjqjoj1aZ1uYBj4Tmp7Djg7Il6QdAFwj6TzAJXYT4ylPxGxAlgB0NbWFu3t7WPZ3Kxm/Fu1elBWYETERUdrl9QJfASYlw4zERH7gH1p+SFJTwJvpziiyB62agZ2peXfSJqWRhfTgN+W028zMxu7Sl4lNR+4AfjbiPhDpn6GpIa0/DaKJ7d3pENOr0h6b7o6ajGwPm22AehMy52ZupmZVUklz2H8AzAZuD9dHbs5XRH1AeCzkoaBEeDqiHgxbXMN8C3g9cAP0gvgFuAuSV3AM8AVFey3mZmVULHAiIhzj1C/G7j7CG1bgNYS9ReAeePaQTMzGxPf6W1mZrk4MMzMLBcHhpmZ5eLAMDOzXBwYZmaWiwPDzMxycWCYmVkuDgwzM8vFgWFmZrk4MMzMLBcHhpmZ5eLAMDOzXBwYZmaWiwPDzMxycWCYmVkuDgwzM8ulklO0fkbSs5K2ptdfZ9pukjQoabukD2fq81NtUNKNmfpMSQ9KekLSGkknV6rfZmZWWqVHGF+KiPPT614ASbOBRcB5wHzga5Ia0jzfXwUuAWYDHWldgFvTvmYBLwFdFe63WcWkKYtffTerF7U4JLUAWB0R+yLiKWAQeHd6DUbEjojYD6wGFqj4r+qDwNq0/Urg0hr022xcRMRB72b1otKBcZ2kRyTdKektqTYd2JlZZyjVjlSfCvwuIoYPqZuZWRU1lrOxpI3AmSWauoGvA58DIr1/AVgClBqHB6XDK46yfqn+LAWWAjQ1NVEoFI7+BcwmCP9WrR6UFRgRcVGe9SR9E/jn9HEIOCvT3AzsSsul6ruBUyU1plFGdv1D+7MCWAHQ1tYW7e3t+b6IWY35t2r1oJJXSU3LfLwMeCwtbwAWSZosaSYwC/g58AtgVroi6mSKJ8Y3RPFAbz+wMG3fCayvVL/NzKy0skYYx3CbpPMpHj76NfB3ABGxTdJdwOPAMHBtRIwASLoOuA9oAO6MiG1pXzcAqyXdDDwM9Faw32YVI4nGxkb+/Oc/M2nSJIaHh33y2+qGTtQfa1tbW2zZsqXW3TB71dEuoz1R/x1a/ZH0UES0lWrznd5mZpaLA8PMzHJxYJiZWS4ODLMqu+aaa/je977HNddcU+uumI2JT3qbVYlPels98Elvswli8uTJTJo0CYBJkyYxefLkGvfILD8HhlmVnHTSSezfv5+pU6dy0kknMXXqVPbv389JJ/mfodUH/1LNquTAgQMAPP/88xw4cIDnn3/+oLrZROfAMKuSyZMnc+GFF9LYWHzAQmNjIxdeeKEPS1ndqOSjQcwsY//+/WzevJnbbruN2bNn8/jjj/OpT33KIwyrGw4Msyo5+eSTWbhwIXfeeScDAwO0tLSwaNEi1q5de+yNzSYAB4ZZlezfv5+f/vSn9Pb2MjIyQkNDA11dXezfv7/WXTPLxYFhViWzZ8/m0ksvZdmyZa+OMK688kruueeeWnfNLBcHhlmVdHd3093dfdgIo6enp9ZdM8vFgWFWJR0dHQAHjTB6enperZtNdH40iFkNFAoFT8tqE5IfDWJmZmWr5JzeayRtTa9fS9qa6jMk/THTdkdmmwskPSppUNKXlZ7WJuk0SfdLeiK9v6VS/TYzs9IqFhgR8dGIOD8izgfuBv5PpvnJ0baIuDpT/zqwFJiVXvNT/UbggYiYBTyQPpvVnb6+PlpbW5k3bx6tra309fXVuktmuVX8kFQaJfwn4Kj/MiRNA94cET+L4omVVcClqXkBsDItr8zUzepGX18fy5cvZ+/evQDs3buX5cuXOzSsblTjKqn3A7+JiCcytZmSHgZ+D3w6In4CTAeGMusMpRpAU0Q8BxARz0l6a6k/JGkpxREKTU1NFAqFcf0iZuW4/vrrOXDgANdffz0zZ87kqaee4uabb+b6669n2rRpte6e2TGVFRiSNgJnlmjqjoj1abmDg0cXzwFnR8QLki4A7pF0HlBqdpkxXcIVESuAFVC8SspXodhEsnv3bn74wx9y8cUXUygU+MQnPkFraysf+tCHfMWU1YWyAiMiLjpau6RG4HLggsw2+4B9afkhSU8Cb6c4omjObN4M7ErLv5E0LY0upgG/LaffZmY2dpU+h3ER8KuIePVQk6QzJDWk5bdRPLm9Ix1yekXSe9N5j8XA6ChlA9CZljszdbO60dzczOLFi+nv72d4eJj+/n4WL15Mc3PzsTc2mwAqfQ5jEYef7P4A8FlJw8AIcHVEvJjargG+Bbwe+EF6AdwC3CWpC3gGuKLC/TYbd7fddhvLly9nyZIlPP3005xzzjmMjIzwxS9+sdZdM8ulooEREf+5RO1uipfZllp/C9Baov4CMG+8+2dWTaOPAOnp6UESU6ZM4fOf/7wfDWJ1w48GMasBPxrEJio/GsTMzMrmwDAzs1wcGGZmlosDw6yK/Cwpq2eeQMmsSvr6+krOuAf4SimrCx5hmFVJT08Pvb29zJ07l8bGRubOnUtvb6+naLW64cAwq5KBgQHmzJlzUG3OnDkMDAzUqEdmY+PAMKuSlpYWNm3adFBt06ZNtLS01KhHZmPjwDCrku7ubrq6ug56llRXVxfd3d217ppZLj7pbVYloye2ly1bxsDAAC0tLfT09PiEt9UNPxrErAb8aBCbqPxoEDMzK5sDw8zMcnFgmJlZLg4MMzPLpezAkHSFpG2SDkhqO6TtJkmDkrZL+nCmPj/VBiXdmKnPlPSgpCckrZF0cqpPTp8HU/uMcvttZmZjMx4jjMeAy4EfZ4uSZlOcovU8YD7wNUkNaT7vrwKXALOBjrQuwK3AlyJiFvAS0JXqXcBLEXEu8KW0npmZVVHZgRERAxGxvUTTAmB1ROyLiKeAQeDd6TUYETsiYj+wGlggScAHgbVp+5XApZl9rUzLa4F5aX0zM6uSSt64Nx3YnPk8lGoAOw+pvweYCvwuIoZLrD99dJuIGJb0clp/d/YPSloKLAVoamqiUCiM13cxG1d79uzx79PqTq7AkLQROLNEU3dErD/SZiVqQelRTRxl/aPt6+BCxApgBRRv3PONUTZR+cY9q0e5AiMiLjqOfQ8BZ2U+NwO70nKp+m7gVEmNaZSRXX90X0OSGoFTgBePo09mZnacKnlZ7QZgUbrCaSYwC/g58AtgVroi6mSKJ8Y3RPEZJf3AwrR9J7A+s6/OtLwQ+FGcqM80MTOboMbjstrLJA0B7wO+L+k+gIjYBtwFPA78C3BtRIyk0cN1wH3AAHBXWhfgBuCTkgYpnqPoTfVeYGqqfxJ49VJcMzOrjrJPekfEOmDdEdp6gMOmE4uIe4F7S9R3ULyK6tD6n4Aryu2rmZkdP9/pbWZmuTgwzMwsFweGmZnl4sAwM7NcHBhmZpaLA8PMzHJxYJiZWS4ODDMzy8WBYWZmuTgwzKqor6+P1tZW5s2bR2trK319fbXuklluDgyzKunr62P58uXs3buXiGDv3r0sX77coWF1QyfqQ1/b2tpiy5Ytte6G2avOOusshoeH+e53v8vIyAgNDQ1ceeWVNDY2snPnzmPvwKwKJD0UEW2l2jzCMKuSoaEhVq1axdy5c2lsbGTu3LmsWrWKoaGhWnfNLBcHhpmZ5eLAMKuS5uZmOjs76e/vZ3h4mP7+fjo7O2lubq5118xyKXs+DDPL57bbbmP58uUsWbKEZ555hrPPPpvh4WG+8IUv1LprZrmUNcKQdIWkbZIOSGrL1C+W9JCkR9P7BzNtBUnbJW1Nr7em+mRJayQNSnpQ0ozMNjel+nZJHy6nz2a10tHRwe23386UKVMAmDJlCrfffjsdHR017plZPuWOMB4DLge+cUh9N/A3EbFLUivF6VinZ9qviohDL2HqAl6KiHMlLQJuBT4qaTbFeb/PA/4C2Cjp7RExUmbfzaquo6ODjo4OCoUC7e3tte6O2ZiUNcKIiIGI2F6i/nBE7EoftwGvkzT5GLtbAKxMy2uBeZKU6qsjYl9EPAUMUmIaVzMzq6xqnMP4j8DDEbEvU/tHSSPA3cDNUbwZZDqwEyAihiW9DExN9c2ZbYc4eLTyKklLgaUATU1NFAqFcf4qZuNjz549/n1a3TlmYEjaCJxZoqk7ItYfY9vzKB5a+lCmfFVEPCvpTRQD4+PAKkAldhFHqR9ejFgBrIDijXse8ttE5UNSVo+OGRgRcdHx7FhSM7AOWBwRT2b292x6f0XSdykeXlpFceRwFjAkqRE4BXgxUx/VDOzCzMyqqiL3YUg6Ffg+cFNE/N9MvVHS6Wl5EvARiifOATYAnWl5IfCjdKhqA7AoXUU1E5gF/LwS/TYzsyMr97LayyQNAe8Dvi/pvtR0HXAu8D8OuXx2MnCfpEeArcCzwDfTNr3AVEmDwCeBGwEiYhtwF/A48C/Atb5Cysys+vzwQbMa8DkMm6j88EEzMyubA8PMzHJxYJiZWS4ODDMzy8WBYWZmuTgwzMwsFweGmZnl4sAwM7NcHBhmZpaLA8PMzHJxYJiZWS4ODDMzy8WBYWZmuTgwzMwsFweGmZnl4sAwM7Ncyp1x7wpJ2yQdkNSWqc+Q9MfMbHt3ZNoukPSopEFJX5akVD9N0v2Snkjvb0l1pfUGJT0i6V3l9NnMzI5PuSOMx4DLgR+XaHsyIs5Pr6sz9a8DSynOzT0LmJ/qNwIPRMQs4IH0GeCSzLpL0/ZmZlZlZQVGRAxExPa860uaBrw5In4WxblhVwGXpuYFwMq0vPKQ+qoo2gycmvZjZmZV1FjBfc+U9DDwe+DTEfETYDowlFlnKNUAmiLiOYCIeE7SW1N9OrCzxDbPHfoHJS2lOAqhqamJQqEwft/GbBzt2bPHv0+rO8cMDEkbgTNLNHVHxPojbPYccHZEvCDpAuAeSecBKrFuHKsLebeJiBXACoC2trZob28/xq7NaqNQKODfp9WbYwZGRFw01p1GxD5gX1p+SNKTwNspjg6aM6s2A7vS8m8kTUuji2nAb1N9CDjrCNuYmVmVVOSyWklnSGpIy2+jeMJ6Rzrk9Iqk96aroxYDo6OUDUBnWu48pL44XS31XuDl0UNXZmZWPeVeVnuZpCHgfcD3Jd2Xmj4APCLp34C1wNUR8WJquwb438Ag8CTwg1S/BbhY0hPAxekzwL3AjrT+N4H/Wk6fzczs+JR10jsi1gHrStTvBu4+wjZbgNYS9ReAeSXqAVxbTj/NzKx8vtPbzMxycWCYmVkuDgwzM8vFgWFmZrk4MMzMLBcHhpmZ5eLAMDOzXBwYZmaWiwPDzMxycWCYmVkuDgwzM8vFgWFmZrk4MMzMLBcHhpmZ5eLAMDOzXBwYZmaWS7kz7l0haZukA5LaMvWrJG3NvA5IOj+1FSRtz7S9NdUnS1ojaVDSg5JmZPZ3U6pvl/ThcvpsZmbHp6wZ94DHgMuBb2SLEfEd4DsAkt4BrI+IrZlVrkoz72V1AS9FxLmSFgG3Ah+VNBtYBJwH/AWwUdLbI2KkzL6bmdkYlDXCiIiBiNh+jNU6gL4cu1sArEzLa4F5kpTqqyNiX0Q8RXFu73cfb5/NzOz4lDvCyOOjFP+jn/WPkkYozvt9c5q3ezqwEyAihiW9DExN9c2ZbYdS7TCSlgJLAZqamigUCuP4NczGz549e/z7tLpzzMCQtBE4s0RTd0SsP8a27wH+EBGPZcpXRcSzkt5EMTA+DqwCVGIXcZT64cWIFcAKgLa2tmhvbz9a98xqplAo4N+n1ZtjBkZEXFTG/hdxyOGoiHg2vb8i6bsUDy+tojhyOAsYktQInAK8mKmPagZ2ldEnMzM7DhW7rFbSScAVwOpMrVHS6Wl5EvARiifOATYAnWl5IfCjdKhqA7AoXUU1E5gF/LxS/TYzs9LKOoch6TLgK8AZwPclbY2I0ctePwAMRcSOzCaTgftSWDQAG4FvprZe4NuSBimOLBYBRMQ2SXcBjwPDwLW+QsrMrPrKCoyIWAesO0JbAXjvIbW9wAVHWP9PFEckpdp6gJ5y+mpmZuXxnd5mZpaLA8PMzHJxYJiZWS4ODDMzy8WBYWZmuTgwzKqor6+P1tZW5s2bR2trK319eR6zZjYxVONZUmZGMSy6u7vp7e1lZGSEhoYGurq6AOjo6Khx78yOzSMMsyrp6emht7eXuXPn0tjYyNy5c+nt7aWnx7cYWX1wYJhVycDAAHPmzDmoNmfOHAYGBmrUI7OxcWCYVUlLSwubNm06qLZp0yZaWlpq1COzsXFgmFVJd3c3XV1d9Pf3Mzw8TH9/P11dXXR3d9e6a2a5+KS3WZWMnthetmwZAwMDtLS00NPT4xPeVjdUfIL4iaetrS22bDl02nCzicETKNlEJemhiGgr1eZDUmZV5PswrJ75kJRZlfg+DKt3HmGYVYnvw7B6V3ZgSPp7Sb+S9IikdZJOzbTdJGlQ0nZJH87U56faoKQbM/WZkh6U9ISkNZJOTvXJ6fNgap9Rbr/Nqs33YVi9G48Rxv1Aa0S8E/h34CYASbMpTrN6HjAf+JqkBkkNwFeBS4DZQEdaF+BW4EsRMQt4CehK9S7gpYg4F/hSWs+srvg+DKt3ZQdGRPwwIobTx81Ac1peAKyOiH0R8RQwCLw7vQYjYkdE7AdWAwskCfggsDZtvxK4NLOvlWl5LTAvrW9WN3wfhtW78T7pvQRYk5anUwyQUUOpBrDzkPp7gKnA7zLhk11/+ug2ETEs6eW0/u7sH5e0FFgK0NTURKFQKP8bmY2TadOmcdVVV7FkyRKeeeYZzj77bD72sY8xbdo0/1atLuQKDEkbgTNLNHVHxPq0TjcwDHxndLMS6welRzVxlPWPtq+DCxErgBVQvA/D17nbRNPe3s7nPvc534dhdSlXYETERUdrl9QJfASYF///TsAh4KzMas3ArrRcqr4bOFVSYxplZNcf3deQpEbgFODFPH03M7PxMR5XSc0HbgD+NiL+kGnaACxKVzjNBGYBPwd+AcxKV0SdTPHE+IYUNP3AwrR9J7A+s6/OtLwQ+FGcqLeom5lNUONxDuMfgMnA/ek89OaIuDoitkm6C3ic4qGqayNiBEDSdcB9QANwZ0RsS/u6AVgt6WbgYaA31XuBb0sapDiyWDQO/TYzszEoOzDSpa5HausBDrsrKSLuBe4tUd9B8SqqQ+t/Aq4or6dmZlYO3+ltZma5nLBPq5X0PPB0rfthdgSnc8hl4WYTxDkRcUaphhM2MMwmMklbjvQIabOJyoekzMwsFweGmZnl4sAwq40Vte6A2Vj5HIaZmeXiEYaZmeXiwDAzs1wcGGZjJKlb0rY0y+RWSe+p0N/5jKT/Xol9mx2P8Z4Pw+yEJul9FJ/M/K6I2CfpdODkGnfLrCo8wjAbm2nA7ojYBxARuyNil6T/KekXkh6TtGJ0RkhJ50raKOnfJP1S0l9KeqOkB9LnRyUtGN15Gr1sT3PQ/FWmfr6kzWlUs07SW6r9xc18lZTZGEh6I7AJeAOwEVgTEf8q6bSIeDGt823groj4nqQHgVsiYp2k11H8n7T9wBsi4vdphLKZ4uP/3wV8i+IMlI3AL4E7IuJ/SXoEWJb+1meBN0fEf6vmdzfzISmzMYiIPZIuAN4PzAXWSLoReEXSpygGyWnANkkFYHpErEvb/glA0iTg85I+ABygOAVxU9rnutF5ZSRtSO+nAKdGxL+mbqwE/qka39csy4FhNkZpXpcCUJD0KPB3wDuBtojYKekzwOsoPbUwwFXAGcAFEfFnSb9O60OJqYfNJgqfwzAbA0l/JWlWpnQ+sD0t706HrBYCRMTvKU4rfGnadrKkN1CcYvi3KSzmAuek7X8MXCbp9ZLeBPxN2s/LwEuS3p/W+zgwOtowqxqPMMzG5o3AVySdSnEmyUFgKfA74FHg1xSnIR71ceAb6bzDnylOBPYd4HuStgBbgV8BRMQvJa1JtaeBn2T20wnckQJnB/BfKvUFzY7EJ73NzCwXH5IyM7NcHBhmZpaLA8PMzHJxYJiZWS4ODDMzy8WBYWZmuTgwzMwsl/8Ha2WwVs1KD2kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[['Sacado']].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeking for N.A. values\n",
    "\n",
    "This dataset does not present N.A./Blank values.\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.index.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>na</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>columns</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PP1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP13</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP16</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP17</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP22</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP23</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP27</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PP28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sacado</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraude</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         na\n",
       "columns    \n",
       "PP1       0\n",
       "PP2       0\n",
       "PP3       0\n",
       "PP4       0\n",
       "PP5       0\n",
       "PP6       0\n",
       "PP7       0\n",
       "PP8       0\n",
       "PP9       0\n",
       "PP10      0\n",
       "PP11      0\n",
       "PP12      0\n",
       "PP13      0\n",
       "PP14      0\n",
       "PP15      0\n",
       "PP16      0\n",
       "PP17      0\n",
       "PP18      0\n",
       "PP19      0\n",
       "PP20      0\n",
       "PP21      0\n",
       "PP22      0\n",
       "PP23      0\n",
       "PP24      0\n",
       "PP25      0\n",
       "PP26      0\n",
       "PP27      0\n",
       "PP28      0\n",
       "Sacado    0\n",
       "Fraude    0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_na = {\n",
    "    'columns': list(df.columns),\n",
    "    'na': []\n",
    "}\n",
    "\n",
    "for i in range(len(df.columns)):\n",
    "    dict_na.get('na').append(sum(df[df.columns[i]].isna()))\n",
    "\n",
    "pandas.DataFrame(dict_na).set_index('columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does this dataset is non-balanced?\n",
    "\n",
    "This section aims on checking if the dataset is non-balanced - are more frauds than non-frauds? Vice-Versa?\n",
    "\n",
    "Table below assumes that the y variable - Fraude - has only 2 unique values - presented in table.\n",
    "\n",
    "```python\n",
    "df.Fraude.unique()\n",
    "```\n",
    "\n",
    "| Value | Meaning   | Total    | Percentage |\n",
    "| :---: | :-------: | :------: | :--------: |\n",
    "| 0     | Non Fraud | 149.763  | 99,842 %   |\n",
    "| 1     | Fraud     | 237      | 0,0158 %   |\n",
    "\n",
    "As can be observed on the table above. It's been assumed that 0 represents a non-fraudulent transaction and 1 represents a fraudulent transaction. This dataset is pretty unbalanced - with less than 1 % being fraudulent transactions (237 data entries). This scenario, on model training steps would be a problem - the model probably will be overfitted in fraudulents occurrences. To prevent it, it must be added some new - artificially generated or naturally acquired - fraudulents data entries.\n",
    "\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many unique entries this variable presents.\n",
    "df.Fraude.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149763\n",
      "0.99842\n"
     ]
    }
   ],
   "source": [
    "# Checking how many data entries are non-fraud or 0\n",
    "print(len(df[df['Fraude'] == 0]))\n",
    "\n",
    "# Checking the percentage of non-fraud transactions\n",
    "print(len(df[df['Fraude'] == 0])/len(df.Fraude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00158\n"
     ]
    }
   ],
   "source": [
    "# Checking how many data entries are fraud or 1\n",
    "len(df[df['Fraude'] == 1])\n",
    "\n",
    "# Checking the percentage of fraud transactions\n",
    "print(len(df[df['Fraude'] == 1])/len(df.Fraude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction\n",
    "\n",
    "This section aims on reduct the dimensionality of this dataset.\n",
    "\n",
    "__It can be used:__\n",
    "\n",
    "- linear regression, correlation and statistically relevance;\n",
    "- PCA;\n",
    "\n",
    "_obs: despite the robustness of PCA, some articles presents issues on its performance - losing to simpler techniques._\n",
    "\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrence = pandas.Series(df.index)\n",
    "\n",
    "x = pandas.DataFrame(df[df.columns[1:-1]])\n",
    "y = pandas.DataFrame(df[df.columns[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Linear Regression\n",
    "lm = linear_model.LinearRegression().fit(x, y)\n",
    "\n",
    "attr_reduction = SelectFromModel(lm, prefit=True)\n",
    "\n",
    "df_pca = pandas.DataFrame(attr_reduction.transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Predictors\n",
    "\n",
    "Three models will be implemented - if none of them supply the needs, new models could be choosen - and compared. Not only the assertiveness rate will be considered. The most problematic issue are False Negatives occurences - when the occurrence is Fraudulent however the model classified it as a Non-fraudulent occurence - if this happens the model will \"lose\" some points. False positives could be sent to a human validation - not so problematic as False Negatives.\n",
    "\n",
    "__Models__:\n",
    "- Linear Regression;\n",
    "- Support Vector Machines;\n",
    "- Random Forest.\n",
    "\n",
    "_obs: Random forest classifier, when compared with other classifiers, presented 1 advantage point and 1 disavantage point - it wasn't able to converge in polynomial time (when compared to Linear Regression and SVM's times - much bigger time to converge), however it presented the most precise classifiers between all 3 - With lesser False Negatives._\n",
    "\n",
    "_obs: Due the results. A grid search with SVM and Random Forest will not be needed_\n",
    "\n",
    "On this scenario, even with time complexity being an issue - when pipelined in production - the random forest will be chosen into \"production\" step.\n",
    "\n",
    "_obs: My concerns come to reality. All 3 models classifies pretty well non fraudulent transactions. However - due the lack of data - all 3 - at some point and in some level - presented an overfitting in classifying Fraudulent transactions - a further study will be made with Random Forest - the model with the most precise behaviour._\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_separation(df, proportion=0.2):\n",
    "    \"\"\"\n",
    "    Data separation method.\n",
    "    \"\"\"\n",
    "    return train_test_split(df, test_size=proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_screening(dt):\n",
    "    \"\"\"\n",
    "    Fitting time performance calculator.\n",
    "    \"\"\"\n",
    "    print(datetime.datetime.now() - dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'linear_model': {\n",
    "        'train': [],\n",
    "        'test': [],\n",
    "        'validation': []\n",
    "    },\n",
    "    'svm': {\n",
    "        'train': [],\n",
    "        'test': [],\n",
    "        'validation': []\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'train': [],\n",
    "        'test': [],\n",
    "        'validation': []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data_separation(df)\n",
    "test, validation = data_separation(test, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train - x and y\n",
    "x_train = pandas.DataFrame(train[train.columns[0:-1]])\n",
    "y_train = pandas.DataFrame(train[train.columns[-1]])\n",
    "\n",
    "# Splitting into test - x and y\n",
    "x_test = pandas.DataFrame(test[test.columns[0:-1]])\n",
    "y_test = pandas.DataFrame(test[test.columns[-1]])\n",
    "\n",
    "# Splitting into validation - x and y\n",
    "x_validation = pandas.DataFrame(validation[validation.columns[0:-1]])\n",
    "y_validation = pandas.DataFrame(validation[validation.columns[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.337315\n"
     ]
    }
   ],
   "source": [
    "# Multiple Linear Regression\n",
    "begin = datetime.datetime.now()\n",
    "\n",
    "lm = linear_model.LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "time_screening(begin)\n",
    "\n",
    "y_train['Predicted'] = lm.predict(x_train)\n",
    "y_train['Predicted'] = y_train['Predicted'].astype(int)\n",
    "\n",
    "y_test['Predicted'] = lm.predict(x_test)\n",
    "y_test['Predicted'] = y_test['Predicted'].astype(int)\n",
    "\n",
    "y_validation['Validation'] = lm.predict(x_validation)\n",
    "y_validation['Validation'] = y_validation['Validation'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.get('linear_model')['train'] = len(y_train[y_train['Fraude'] == y_train['Predicted']])/len(y_train)\n",
    "results.get('linear_model')['test'] = len(y_test[y_test['Fraude'] == y_test['Predicted']])/len(y_test)\n",
    "results.get('linear_model')['validation'] = len(y_validation[y_validation['Fraude'] == y_validation['Validation']])/len(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non Fraud</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non Fraud</th>\n",
       "      <td>119800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>168</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Non Fraud  Fraud\n",
       "Non Fraud     119800      1\n",
       "Fraud            168     31"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(confusion_matrix(y_train[['Fraude']], y_train[['Predicted']]), \n",
    "                 ['Non Fraud', 'Fraud'], ['Non Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non Fraud</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non Fraud</th>\n",
       "      <td>17977</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Non Fraud  Fraud\n",
       "Non Fraud      17977      0\n",
       "Fraud             19      4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(confusion_matrix(y_test[['Fraude']], y_test[['Predicted']]), \n",
    "                 ['Non Fraud', 'Fraud'], ['Non Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non Fraud</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non Fraud</th>\n",
       "      <td>11985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Non Fraud  Fraud\n",
       "Non Fraud      11985      0\n",
       "Fraud             12      3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(confusion_matrix(y_validation[['Fraude']], y_validation[['Validation']]), \n",
    "                 ['Non Fraud', 'Fraud'], ['Non Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:03.284036\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Machine\n",
    "begin = datetime.datetime.now()\n",
    "\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False, max_iter=10000).fit(x_train, y_train.Fraude.values)\n",
    "\n",
    "time_screening(begin)\n",
    "\n",
    "y_train['Predicted'] = lsvc.predict(x_train)\n",
    "y_train['Predicted'] = y_train['Predicted'].astype(int)\n",
    "\n",
    "y_test['Predicted'] = lsvc.predict(x_test)\n",
    "y_test['Predicted'] = y_test['Predicted'].astype(int)\n",
    "\n",
    "y_validation['Validation'] = lsvc.predict(x_validation)\n",
    "y_validation['Validation'] = y_validation['Validation'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.get('svm')['train'] = len(y_train[y_train['Fraude'] == y_train['Predicted']])/len(y_train)\n",
    "results.get('svm')['test'] = len(y_test[y_test['Fraude'] == y_test['Predicted']])/len(y_test)\n",
    "results.get('svm')['validation'] = len(y_validation[y_validation['Fraude'] == y_validation['Validation']])/len(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non Fraud</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non Fraud</th>\n",
       "      <td>119788</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>54</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Non Fraud  Fraud\n",
       "Non Fraud     119788     13\n",
       "Fraud             54    145"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(confusion_matrix(y_train[['Fraude']], y_train[['Predicted']]), \n",
    "                 ['Non Fraud', 'Fraud'], ['Non Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non Fraud</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non Fraud</th>\n",
       "      <td>17974</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Non Fraud  Fraud\n",
       "Non Fraud      17974      3\n",
       "Fraud              8     15"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(confusion_matrix(y_test[['Fraude']], y_test[['Predicted']]), \n",
    "                 ['Non Fraud', 'Fraud'], ['Non Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non Fraud</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non Fraud</th>\n",
       "      <td>11982</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Non Fraud  Fraud\n",
       "Non Fraud      11982      3\n",
       "Fraud              2     13"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(confusion_matrix(y_validation[['Fraude']], y_validation[['Validation']]), \n",
    "                 ['Non Fraud', 'Fraud'], ['Non Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:50.102289\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "begin = datetime.datetime.now()\n",
    "\n",
    "r_forest = RandomForestClassifier(n_estimators=90).fit(x_train, y_train.Fraude.values)\n",
    "\n",
    "time_screening(begin)\n",
    "\n",
    "y_train['Predicted'] = r_forest.predict(x_train)\n",
    "y_train['Predicted'] = y_train['Predicted'].astype(int)\n",
    "\n",
    "y_test['Predicted'] = r_forest.predict(x_test)\n",
    "y_test['Predicted'] = y_test['Predicted'].astype(int)\n",
    "\n",
    "y_validation['Validation'] = r_forest.predict(x_validation)\n",
    "y_validation['Validation'] = y_validation['Validation'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.get('random_forest')['train'] = len(y_train[y_train['Fraude'] == y_train['Predicted']])/len(y_train)\n",
    "results.get('random_forest')['test'] = len(y_test[y_test['Fraude'] == y_test['Predicted']])/len(y_test)\n",
    "results.get('random_forest')['validation'] = len(y_validation[y_validation['Fraude'] == y_validation['Validation']])/len(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non Fraud</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non Fraud</th>\n",
       "      <td>119801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Non Fraud  Fraud\n",
       "Non Fraud     119801      0\n",
       "Fraud              0    199"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(confusion_matrix(y_train[['Fraude']], y_train[['Predicted']]), \n",
    "                 ['Non Fraud', 'Fraud'], ['Non Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non Fraud</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non Fraud</th>\n",
       "      <td>17976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Non Fraud  Fraud\n",
       "Non Fraud      17976      1\n",
       "Fraud              7     16"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(confusion_matrix(y_test[['Fraude']], y_test[['Predicted']]), \n",
    "                 ['Non Fraud', 'Fraud'], ['Non Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non Fraud</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non Fraud</th>\n",
       "      <td>11982</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Non Fraud  Fraud\n",
       "Non Fraud      11982      3\n",
       "Fraud              2     13"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(confusion_matrix(y_validation[['Fraude']], y_validation[['Validation']]), \n",
    "                 ['Non Fraud', 'Fraud'], ['Non Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_model</th>\n",
       "      <th>svm</th>\n",
       "      <th>random_forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.998592</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.999389</td>\n",
       "      <td>0.999556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.999583</td>\n",
       "      <td>0.999583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            linear_model       svm  random_forest\n",
       "train           0.998592  0.999442       1.000000\n",
       "test            0.998944  0.999389       0.999556\n",
       "validation      0.999000  0.999583       0.999583"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using selected model in \"production\" environment\n",
    "\n",
    "- Normalize data\n",
    "- Split data\n",
    "- fit and predict model\n",
    "\n",
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization\n",
    "scaler = preprocessing.MinMaxScaler().fit(df_pca)\n",
    "df_pca_norm = pandas.DataFrame(scaler.transform(df_pca))\n",
    "\n",
    "df_pca_norm['Occurrence'] = occurrence\n",
    "df_pca_norm.set_index('Occurrence', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data separation\n",
    "df_pca_norm['Fraude'] = y\n",
    "\n",
    "train, test = data_separation(df_pca_norm)\n",
    "test, validation = data_separation(test, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train - x and y\n",
    "x_train = pandas.DataFrame(train[train.columns[0:-1]])\n",
    "y_train = pandas.DataFrame(train[train.columns[-1]])\n",
    "\n",
    "# Splitting into test - x and y\n",
    "x_test = pandas.DataFrame(test[test.columns[0:-1]])\n",
    "y_test = pandas.DataFrame(test[test.columns[-1]])\n",
    "\n",
    "# Splitting into validation - x and y\n",
    "x_validation = pandas.DataFrame(validation[validation.columns[0:-1]])\n",
    "y_validation = pandas.DataFrame(validation[validation.columns[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:48.581284\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "begin = datetime.datetime.now()\n",
    "\n",
    "r_forest = RandomForestClassifier(n_estimators=90).fit(x_train, y_train.Fraude.values)\n",
    "\n",
    "time_screening(begin)\n",
    "\n",
    "y_train['Predicted'] = r_forest.predict(x_train)\n",
    "y_train['Predicted'] = y_train['Predicted'].astype(int)\n",
    "\n",
    "y_test['Predicted'] = r_forest.predict(x_test)\n",
    "y_test['Predicted'] = y_test['Predicted'].astype(int)\n",
    "\n",
    "y_validation['Validation'] = r_forest.predict(x_validation)\n",
    "y_validation['Validation'] = y_validation['Validation'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9994444444444445\n",
      "0.9993333333333333\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train[y_train['Fraude'] == y_train['Predicted']])/len(y_train))\n",
    "print(len(y_test[y_test['Fraude'] == y_test['Predicted']])/len(y_test))\n",
    "print(len(y_validation[y_validation['Fraude'] == y_validation['Validation']])/len(y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non Fraud</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non Fraud</th>\n",
       "      <td>119815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Non Fraud  Fraud\n",
       "Non Fraud     119815      0\n",
       "Fraud              0    185"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(confusion_matrix(y_train[['Fraude']], y_train[['Predicted']]), \n",
    "                 ['Non Fraud', 'Fraud'], ['Non Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non Fraud</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non Fraud</th>\n",
       "      <td>17968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Non Fraud  Fraud\n",
       "Non Fraud      17968      2\n",
       "Fraud              8     22"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(confusion_matrix(y_test[['Fraude']], y_test[['Predicted']]), \n",
    "                 ['Non Fraud', 'Fraud'], ['Non Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non Fraud</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non Fraud</th>\n",
       "      <td>11977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Non Fraud  Fraud\n",
       "Non Fraud      11977      1\n",
       "Fraud              7     15"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(confusion_matrix(y_validation[['Fraude']], y_validation[['Validation']]), \n",
    "                 ['Non Fraud', 'Fraud'], ['Non Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if there's overfitting on classifying Frauds - due the low quantity of data entries\n",
    "overfitting = x_validation\n",
    "overfitting['Fraude'] = y_validation['Fraude']\n",
    "\n",
    "aux = x_test\n",
    "aux['Fraude'] = y_test['Fraude']\n",
    "\n",
    "overfitting = overfitting.append(aux)\n",
    "overfitting = overfitting[overfitting['Fraude'] == 1]\n",
    "del(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfitting['Predicted'] = r_forest.predict(overfitting.drop(columns=['Fraude']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7115384615384616\n"
     ]
    }
   ],
   "source": [
    "# Decay of assertiveness rate\n",
    "print(len(overfitting[overfitting['Fraude'] == overfitting['Predicted']])/len(overfitting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non Fraud</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Non Fraud</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Non Fraud  Fraud\n",
       "Non Fraud          0      0\n",
       "Fraud             15     37"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(confusion_matrix(overfitting[['Fraude']], overfitting[['Predicted']]), \n",
    "                 ['Non Fraud', 'Fraud'], ['Non Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing\n",
    "\n",
    "Section aimed on summarizing the methodology of this study and concluding it.\n",
    "\n",
    "#### Checking duplicated values\n",
    "\n",
    "Assuming that the 'Ocorrencia' is a unique code for the transaction itself. Let's check if there's any duplicated occurrence.\n",
    "\n",
    "```python\n",
    "len(df.index.unique())\n",
    "```\n",
    "If the dataset doesn't present any duplicated values, this piece of code should return, as output, 150.000 data entries. Nevertheless it returned only 64.958 values - meaning that this dataset presents around 85.042 duplicated data entries.\n",
    "\n",
    "```python\n",
    "len(df) - len(df.index.unique())\n",
    "```\n",
    "\n",
    "The duplicated values will be kept on analysis and training in modeling step. Due the nature of this dataset, this duplicate values could have been naturally generated - meaning that one occurrence could occur more than once - or, due the lack of available training material, some transactions could have been artificially generated.\n",
    "\n",
    "----------------------------\n",
    "\n",
    "#### Exploratory Analysis\n",
    "\n",
    "Section aimed on checking the data distribution and data behaviour.\n",
    "\n",
    "- N.A. values?\n",
    "- Outliers?\n",
    "- Min.\n",
    "- Max.\n",
    "- Mean.\n",
    "- Stdev.\n",
    "\n",
    "-------------------------\n",
    "\n",
    "#### Describe Exploratory Analysis Result\n",
    "\n",
    "This section summarizes the initial analysis on this dataset.\n",
    "\n",
    "The command below allows to summarize each variable and retrieve the main statistical characteristics. \n",
    "\n",
    "```python\n",
    "df.describe()\n",
    "```\n",
    "\n",
    "The first thing to be noticed is at 'Sacado' variable - the amount of money withdrawn. \n",
    "\n",
    "\n",
    "| Statistical Measurement | Value        |\n",
    "| :---------------------: | :----------: |\n",
    "| Mean                    | -88.602261\t |\n",
    "| Standard Deviation      | 247.302373\t |\n",
    "| Min                     | -19656.53    |\n",
    "| Max                     | -0.00        |\n",
    "\n",
    "How can be observed on this chart. The behaviour of 'Sacado' variable is pretty weird. First of all, this variable presents the highest standard deviation of all variables (247.30).\n",
    "\n",
    "```python\n",
    "df.describe().loc['std'].sort_values(ascending=False).head()\n",
    "```\n",
    "\n",
    "The mean, min and max values are pretty strange as well - with all of them being negative or null values. How this values could be negative/null values if this variable it was meant to represent the total withdrawn value of the transaction?\n",
    "\n",
    "__Possible errors:__\n",
    "\n",
    "- Acquistion errors?\n",
    "- Parsing issues?\n",
    "\n",
    "Other variables seems to behave pretty well (well distributed along the mean value - almost a normal curve) - even didn't knowing what they represent (the max values are high? the min values are low?).\n",
    "\n",
    "_obs: Even with the lower deviation. On training, a simple normalization will be made on this dataset._\n",
    "\n",
    "-------------\n",
    "\n",
    "#### Does this dataset is non-balanced?\n",
    "\n",
    "This section aims on checking if the dataset is non-balanced - are more frauds than non-frauds? Vice-Versa?\n",
    "\n",
    "Table below assumes that the y variable - Fraude - has only 2 unique values - presented in table.\n",
    "\n",
    "```python\n",
    "df.Fraude.unique()\n",
    "```\n",
    "\n",
    "| Value | Meaning   | Total    | Percentage |\n",
    "| :---: | :-------: | :------: | :--------: |\n",
    "| 0     | Non Fraud | 149.763  | 0,9984     |\n",
    "| 1     | Fraud     | 237      | 0,0015     |\n",
    "\n",
    "As can be observed on the table above. It's been assumed that 0 represents a non-fraudulent transaction and 1 represents a fraudulent transaction. This dataset is pretty unbalanced - with less than 1 % being fraudulent transactions (237 data entries). This scenario, on model training steps would be a problem - the model probably will be overfitted in fraudulents occurrences. To prevent it, it must be added some new - artificially generated or naturally acquired - fraudulents data entries.\n",
    "\n",
    "----------------------------------------\n",
    "\n",
    "#### Dimensionality Reduction\n",
    "\n",
    "This section aims on reduct the dimensionality of this dataset.\n",
    "\n",
    "__It can be used:__\n",
    "\n",
    "- linear regression, correlation and statistically relevance;\n",
    "- PCA;\n",
    "\n",
    "_obs: despite the robustness of PCA, some articles presents issues on its performance - losing to simpler techniques._\n",
    "\n",
    "-----------------------\n",
    "\n",
    "#### Building Predictors\n",
    "\n",
    "Three models will be implemented - if none of them supply the needs, new models could be choosen - and compared. Not only the assertiveness rate will be considered. The most problematic issue are False Negatives occurences - when the occurrence is Fraudulent however the model classified it as a Non-fraudulent occurence - if this happens the model will \"lose\" some points. False positives could be sent to a human validation - not so problematic as False Negatives.\n",
    "\n",
    "__Models__:\n",
    "- Linear Regression;\n",
    "- Support Vector Machines;\n",
    "- Random Forest.\n",
    "\n",
    "_obs: Random forest classifier, when compared with other classifiers, presented 1 advantage point and 1 disavantage point - it wasn't able to converge in polynomial time (when compared to Linear Regression and SVM's times - much bigger time to converge), however it presented the most precise classifiers between all 3 - With lesser False Negatives._\n",
    "\n",
    "_obs: Due the results. A grid search with SVM and Random Forest will not be needed_\n",
    "\n",
    "On this scenario, even with time complexity being an issue - when pipelined in production - the random forest will be chosen into \"production\" step.\n",
    "\n",
    "_obs: My concerns come to reality. All 3 models classifies pretty well non fraudulent transactions. However - due the lack of data - all 3 - at some point and in some level - presented an overfitting in classifying Fraudulent transactions - a further study will be made with Random Forest - the model with the most precise behaviour._\n",
    "\n",
    "------------------------\n",
    "\n",
    "#### Using selected  model - Random Forest - in \"production\" environment\n",
    "\n",
    "__Steps:__\n",
    "- Normalize data;\n",
    "- Split data;\n",
    "- fit and predict model.\n",
    "\n",
    "Due the normalization and - mainly - the dim reduction, the Random Forest's time performance has increased. During the development time the fitting time was about 0:01:50.102289. In _\"production\"_ time this time has decresead to 0:00:48.581284 - a time reduction of 0:01:01.521005.\n",
    "\n",
    "```python\n",
    "str(datetime.datetime.strptime('0:01:50.102289', '%H:%M:%S.%f') -\n",
    "    datetime.datetime.strptime('0:00:48.581284', '%H:%M:%S.%f'))\n",
    "```\n",
    "\n",
    "The model precision is presented in table below:\n",
    "\n",
    "\n",
    "| Environment      | Train  | Test   | Validation | Overfitting |\n",
    "| :--------------: | :----: | :----: | :--------: | :---------: |\n",
    "| Dev              | 1,0000 | 0,9995 | 0,9995     | ----------- |\n",
    "| Prod             | 1,0000 | 0,9994 | 0,9993     | 0,7115      |\n",
    "\n",
    "As could be observed. During the _\"dev\"_ time - without normalization and dimension reduction - the model achieved good results. The normalization - minmax normalization - and dimension reduction - from 29 variables to only 9 - achieved overwhelming results in time complexity - as mentioned before. Nevertheless, as mentioned, a further study on this model performance was required - __does the lack of fraudlent data overfits the model?__. \n",
    "To test it the test and validation dataframes were merged and only fraudulent data was selected - resulting in a dataframe with 52 data entries (didn't include the train fraudulent data) - and passed to model predictor. The model should've predicted all as Frauds, however, the most problematic case appeared - Frauds classified as Non Frauds (False Negatives).<br>\n",
    "In summary, a good non-fraud classifier was built - with little cases of False Positives (Non Frauds classified as Fraud) - however, as mentioned before, the most problematic case - False Negatives - occur more frequently. To correct it, appart from the selected model - since simpler until the most robust ones (Linear Regression, Bayes, Adaboost, Tree Classifiers, SVM's or Neural Nets) - it needed to add new fraudulent data entries on this dataset - artificially generated or not.\n",
    "\n",
    "-----------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
